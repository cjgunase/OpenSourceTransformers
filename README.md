# OpenSourceTransformers
This is github repo to store all notes and documents related to this program
Of course! Here it is:

# 3-Year Curriculum for Learning Transformer Networks

## Year 1: Introduction to Machine Learning and Basic Mathematics

### Mathematical Foundation

1. **Linear Algebra**: Essential for understanding data structures used in ML.
    - [Khan Academy's Linear Algebra](https://www.khanacademy.org/math/linear-algebra)

2. **Calculus**: Essential for understanding how learning happens in ML.
    - [Khan Academy's Calculus](https://www.khanacademy.org/math/calculus-1)

3. **Probability and Statistics**: Essential for understanding how decision making happens in ML.
    - [Khan Academy's Statistics and Probability](https://www.khanacademy.org/math/statistics-probability)

### Python Programming

Python is the most commonly used programming language in the field of Machine Learning.
- [Codecademy's Learn Python](https://www.codecademy.com/learn/learn-python-3)

### Introduction to Machine Learning

Covers basics of machine learning, various types of algorithms and practical implementation.
- [Coursera's Machine Learning by Andrew Ng](https://www.coursera.org/learn/machine-learning)

---

## Year 2: Deep Learning and Neural Networks

### Deep Learning Specialization

Covers neural networks, deep learning, structuring machine learning projects, convolutional networks, sequence models etc.
- [Deep Learning Specialization by Andrew Ng on Coursera](https://www.coursera.org/specializations/deep-learning)

### Convolutional Neural Networks

Special type of neural networks very effective for image related tasks.
- [Stanford's CS231n: Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu/)

### Recurrent Neural Networks

Special type of neural networks very effective for sequence related tasks like text, time series etc.
- [Coursera's Sequence Models by Andrew Ng](https://www.coursera.org/learn/nlp-sequence-models)

---

## Year 3: Advanced Topics and Transformers

### Natural Language Processing

Basic understanding of NLP is needed before moving to transformers.
- [Coursera's Natural Language Processing Specialization](https://www.coursera.org/specializations/natural-language-processing)

### Attention Mechanisms

Understanding attention mechanisms is essential as Transformers are based on this concept.
- [Coursera's Sequence Models and Attention Mechanism](https://www.coursera.org/learn/sequence-models-attention-mechanism)

### Transformers

A deep dive into Transformer models which are primarily used in tasks related to Natural Language Processing.
- [The Illustrated Transformer by Jay Alammar](http://jalammar.github.io/illustrated-transformer/)
- [Transformers for Natural Language Processing](https://www.packtpub.com/product/transformers-for-natural-language-processing/9781800565791)

---

**Note**: Although I've divided this into a 3-year plan, the pace can be adjusted according to your comfort and understanding. It's important to practice and implement as you learn these topics to reinforce your understanding. You should work on mini-projects and participate in competitions on platforms like [Kaggle](https://www.kaggle.com/) to get hands-on.


You can copy this markdown directly into a README.md file in a new GitHub repository. The links and formatting should work correctly when viewed on GitHub.
